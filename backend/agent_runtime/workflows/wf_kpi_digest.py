"""
WF-05: KPI Digest

ì£¼ê°„/ì›”ê°„ KPI ë¦¬í¬íŠ¸ ìƒì„± + ì§€ì—° Play/Action ê²½ê³ 

íŠ¸ë¦¬ê±°:
- /ax:kpi-digest ì»¤ë§¨ë“œ
- ì£¼ê°„ ë°°ì¹˜ (ê¸ˆìš”ì¼ EOD)

íë¦„:
1. ê¸°ê°„ ê³„ì‚° (ì£¼ê°„/ì›”ê°„)
2. ë©”íŠ¸ë¦­ ì§‘ê³„ (Activity, Signal, Brief, S2, S3)
3. ë¦¬ë“œíƒ€ì„ ê³„ì‚° (Signalâ†’Brief, Briefâ†’S2)
4. ê²½ê³  ìƒì„± (ëª©í‘œ ë¯¸ë‹¬, ë¦¬ë“œíƒ€ì„ ì´ˆê³¼, ì§€ì—° Play)
5. Top Plays ì„ ì •
6. ì¶”ì²œ ì‚¬í•­ ìƒì„±
7. (ì„ íƒ) Confluence ë¦¬í¬íŠ¸ ë°œí–‰ + ì•Œë¦¼

PoC ëª©í‘œ:
- Activity 20+/ì£¼
- Signal 30+/ì£¼
- Brief 6+/ì£¼
- S2 2~4/ì£¼
- Signalâ†’Brief â‰¤7ì¼
- Briefâ†’S2 â‰¤14ì¼
"""

from dataclasses import dataclass, field
from datetime import UTC, datetime, timedelta
from enum import Enum
from typing import Any

import structlog

logger = structlog.get_logger()


# ============================================================
# Enums & Constants
# ============================================================


class AlertSeverity(str, Enum):
    """ê²½ê³  ì‹¬ê°ë„"""

    INFO = "INFO"
    YELLOW = "YELLOW"
    RED = "RED"


class AlertType(str, Enum):
    """ê²½ê³  ìœ í˜•"""

    UNDER_TARGET = "UNDER_TARGET"
    LEAD_TIME_EXCEEDED = "LEAD_TIME_EXCEEDED"
    PLAY_DELAYED = "PLAY_DELAYED"
    PLAY_STALE = "PLAY_STALE"
    OVERDUE = "OVERDUE"


# PoC ëª©í‘œ ê¸°ì¤€
POC_TARGETS = {
    "activity_weekly": 20,
    "signal_weekly": 30,
    "brief_weekly": 6,
    "s2_weekly_min": 2,
    "s2_weekly_max": 4,
    "signal_to_brief_days": 7,
    "brief_to_s2_days": 14,
}


# ============================================================
# Data Classes
# ============================================================


@dataclass
class KPIInput:
    """KPI Digest ì…ë ¥"""

    period: str = "week"  # week, month
    play_ids: list[str] | None = None  # Noneì´ë©´ ì „ì²´
    notify: bool = False  # Teams/Slack ì•Œë¦¼ ì—¬ë¶€
    include_recommendations: bool = True


@dataclass
class KPITarget:
    """PoC ëª©í‘œ ê¸°ì¤€"""

    activity_weekly: int = 20
    signal_weekly: int = 30
    brief_weekly: int = 6
    s2_weekly_min: int = 2
    s2_weekly_max: int = 4
    signal_to_brief_days: int = 7
    brief_to_s2_days: int = 14


@dataclass
class MetricValue:
    """ê°œë³„ ë©”íŠ¸ë¦­ ê°’"""

    actual: int
    target: int
    achievement: float  # í¼ì„¼íŠ¸
    trend: str = "stable"  # up, down, stable


@dataclass
class LeadTimeMetric:
    """ë¦¬ë“œíƒ€ì„ ë©”íŠ¸ë¦­"""

    avg_days: float
    target_days: int
    on_target: bool
    min_days: float = 0.0
    max_days: float = 0.0
    sample_count: int = 0


@dataclass
class Alert:
    """ê²½ê³  í•­ëª©"""

    type: str
    severity: str
    metric: str
    message: str
    play_id: str | None = None
    details: dict[str, Any] = field(default_factory=dict)


@dataclass
class TopPlay:
    """Top Play í•­ëª©"""

    rank: int
    play_id: str
    play_name: str
    signal_count: int
    brief_count: int
    s2_count: int
    owner: str | None = None


@dataclass
class KPIDigestOutput:
    """KPI Digest ì¶œë ¥"""

    period: str
    period_start: str
    period_end: str
    metrics: dict[str, Any]
    lead_times: dict[str, Any]
    alerts: list[dict[str, Any]]
    top_plays: list[dict[str, Any]]
    recommendations: list[str]
    status_summary: dict[str, int]
    confluence_url: str | None = None
    generated_at: str = ""


# ============================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================


def calculate_period_range(period: str) -> tuple[datetime, datetime]:
    """ê¸°ê°„ ë²”ìœ„ ê³„ì‚°"""
    now = datetime.now(UTC)

    if period == "week":
        # ì´ë²ˆ ì£¼ ì›”ìš”ì¼ 00:00 ~ ì¼ìš”ì¼ 23:59
        start = now - timedelta(days=now.weekday())
        start = start.replace(hour=0, minute=0, second=0, microsecond=0)
        end = start + timedelta(days=6, hours=23, minutes=59, seconds=59)
    elif period == "month":
        # ì´ë²ˆ ë‹¬ 1ì¼ ~ ë§ì¼
        start = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
        next_month = (now.replace(day=28) + timedelta(days=4)).replace(day=1)
        end = next_month - timedelta(seconds=1)
    else:
        # ê¸°ë³¸ 7ì¼
        end = now
        start = now - timedelta(days=7)

    return start, end


def calculate_achievement(actual: int, target: int) -> float:
    """ëª©í‘œ ë‹¬ì„±ë¥  ê³„ì‚°"""
    if target == 0:
        return 100.0 if actual > 0 else 0.0
    return round((actual / target) * 100, 1)


def determine_severity(achievement: float) -> str:
    """ë‹¬ì„±ë¥ ì— ë”°ë¥¸ ì‹¬ê°ë„ ê²°ì •"""
    if achievement >= 80:
        return AlertSeverity.INFO.value
    elif achievement >= 50:
        return AlertSeverity.YELLOW.value
    else:
        return AlertSeverity.RED.value


# ============================================================
# ë©”ì¸ íŒŒì´í”„ë¼ì¸
# ============================================================


class KPIDigestPipeline:
    """
    WF-05: KPI Digest

    íŠ¸ë¦¬ê±°: /ax:kpi-digest, ì£¼ê°„ ë°°ì¹˜ (ê¸ˆìš”ì¼ EOD)
    """

    # ë‹¨ê³„ ì •ì˜
    STEPS = [
        {"id": "PERIOD_CALC", "label": "ê¸°ê°„ ê³„ì‚°"},
        {"id": "METRICS_AGGREGATE", "label": "ë©”íŠ¸ë¦­ ì§‘ê³„"},
        {"id": "LEAD_TIME_CALC", "label": "ë¦¬ë“œíƒ€ì„ ê³„ì‚°"},
        {"id": "ALERTS_GENERATE", "label": "ê²½ê³  ìƒì„±"},
        {"id": "TOP_PLAYS", "label": "Top Plays ì„ ì •"},
        {"id": "RECOMMENDATIONS", "label": "ì¶”ì²œ ì‚¬í•­ ìƒì„±"},
    ]

    def __init__(self):
        self.logger = logger.bind(workflow="WF-05")
        self.targets = KPITarget()

    async def run(self, input_data: KPIInput) -> KPIDigestOutput:
        """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        self.logger.info("Starting KPI Digest", period=input_data.period)

        # 1. ê¸°ê°„ ê³„ì‚°
        period_start, period_end = calculate_period_range(input_data.period)

        # 2. ë©”íŠ¸ë¦­ ì§‘ê³„
        metrics = await self._aggregate_metrics(period_start, period_end, input_data.play_ids)

        # 3. ë¦¬ë“œíƒ€ì„ ê³„ì‚°
        lead_times = await self._calculate_lead_times(period_start, period_end)

        # 4. ê²½ê³  ìƒì„±
        alerts = await self._generate_alerts(metrics, lead_times)

        # 5. Top Plays ì„ ì •
        top_plays = await self._get_top_plays(period_start, period_end)

        # 6. ì¶”ì²œ ì‚¬í•­ ìƒì„±
        recommendations = []
        if input_data.include_recommendations:
            recommendations = self._generate_recommendations(metrics, alerts)

        # 7. ìƒíƒœ ìš”ì•½
        status_summary = await self._get_status_summary()

        # 8. (ì„ íƒ) Confluenceì— ë¦¬í¬íŠ¸ ìƒì„±
        confluence_url = None
        if input_data.notify:
            confluence_url = await self._publish_report(
                input_data.period, metrics, lead_times, alerts, top_plays, recommendations
            )
            await self._send_notifications(confluence_url, alerts)

        self.logger.info(
            "KPI Digest completed",
            alerts_count=len(alerts),
            top_plays_count=len(top_plays),
        )

        # alerts/top_plays íƒ€ì… ë³€í™˜ (Alert/TopPlay â†’ dict)
        alerts_dict: list[dict[str, Any]] = (
            [self._alert_to_dict(a) for a in alerts]
            if alerts and isinstance(alerts[0], Alert)
            else alerts  # type: ignore[assignment]
        )
        top_plays_dict: list[dict[str, Any]] = (
            [self._top_play_to_dict(p) for p in top_plays]
            if top_plays and isinstance(top_plays[0], TopPlay)
            else top_plays  # type: ignore[assignment]
        )

        return KPIDigestOutput(
            period=input_data.period,
            period_start=period_start.isoformat(),
            period_end=period_end.isoformat(),
            metrics=metrics,
            lead_times=lead_times,
            alerts=alerts_dict,
            top_plays=top_plays_dict,
            recommendations=recommendations,
            status_summary=status_summary,
            confluence_url=confluence_url,
            generated_at=datetime.now(UTC).isoformat(),
        )

    def _alert_to_dict(self, alert: Alert) -> dict[str, Any]:
        """Alert ê°ì²´ë¥¼ dictë¡œ ë³€í™˜"""
        return {
            "type": alert.type,
            "severity": alert.severity,
            "metric": alert.metric,
            "message": alert.message,
            "play_id": alert.play_id,
            "details": alert.details,
        }

    def _top_play_to_dict(self, play: TopPlay) -> dict[str, Any]:
        """TopPlay ê°ì²´ë¥¼ dictë¡œ ë³€í™˜"""
        return {
            "rank": play.rank,
            "play_id": play.play_id,
            "play_name": play.play_name,
            "signal_count": play.signal_count,
            "brief_count": play.brief_count,
            "s2_count": play.s2_count,
            "owner": play.owner,
        }

    async def _aggregate_metrics(
        self, start: datetime, end: datetime, play_ids: list[str] | None
    ) -> dict[str, Any]:
        """ë©”íŠ¸ë¦­ ì§‘ê³„ (Mock ë°ì´í„°)"""
        # ì‹¤ì œ êµ¬í˜„ì€ DBì—ì„œ ì¡°íšŒ
        # ì£¼ê°„ ê¸°ì¤€ mock ë°ì´í„°

        activity = MetricValue(
            actual=25,
            target=self.targets.activity_weekly,
            achievement=calculate_achievement(25, self.targets.activity_weekly),
        )

        signal = MetricValue(
            actual=35,
            target=self.targets.signal_weekly,
            achievement=calculate_achievement(35, self.targets.signal_weekly),
        )

        brief = MetricValue(
            actual=8,
            target=self.targets.brief_weekly,
            achievement=calculate_achievement(8, self.targets.brief_weekly),
        )

        s2 = MetricValue(
            actual=3,
            target=self.targets.s2_weekly_min,
            achievement=calculate_achievement(3, self.targets.s2_weekly_min),
        )

        return {
            "activity": {
                "actual": activity.actual,
                "target": activity.target,
                "achievement": activity.achievement,
            },
            "signal": {
                "actual": signal.actual,
                "target": signal.target,
                "achievement": signal.achievement,
            },
            "brief": {
                "actual": brief.actual,
                "target": brief.target,
                "achievement": brief.achievement,
            },
            "s2": {
                "actual": s2.actual,
                "target_min": self.targets.s2_weekly_min,
                "target_max": self.targets.s2_weekly_max,
                "achievement": s2.achievement,
            },
            "s3": {
                "actual": 1,
                "target": 1,
                "achievement": 100.0,
            },
            "by_source": {
                "KT": {"activity": 10, "signal": 15, "brief": 4},
                "ê·¸ë£¹ì‚¬": {"activity": 8, "signal": 12, "brief": 2},
                "ëŒ€ì™¸": {"activity": 7, "signal": 8, "brief": 2},
            },
            "by_channel": {
                "ë°ìŠ¤í¬ë¦¬ì„œì¹˜": {"signal": 12, "brief": 3},
                "ì˜ì—…PM": {"signal": 10, "brief": 3},
                "ì¸ë°”ìš´ë“œ": {"signal": 8, "brief": 1},
                "ì•„ì›ƒë°”ìš´ë“œ": {"signal": 5, "brief": 1},
            },
        }

    async def _calculate_lead_times(self, start: datetime, end: datetime) -> dict[str, Any]:
        """ë¦¬ë“œíƒ€ì„ ê³„ì‚° (Mock ë°ì´í„°)"""
        # ì‹¤ì œ êµ¬í˜„ì€ Signal/Brief ìƒíƒœ ë³€ê²½ ì‹œì  ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°

        signal_to_brief = LeadTimeMetric(
            avg_days=5.2,
            target_days=self.targets.signal_to_brief_days,
            on_target=self.targets.signal_to_brief_days >= 5.2,
            min_days=2.0,
            max_days=10.0,
            sample_count=8,
        )

        brief_to_s2 = LeadTimeMetric(
            avg_days=11.0,
            target_days=self.targets.brief_to_s2_days,
            on_target=self.targets.brief_to_s2_days >= 11.0,
            min_days=5.0,
            max_days=18.0,
            sample_count=3,
        )

        return {
            "signal_to_brief": {
                "avg_days": signal_to_brief.avg_days,
                "target_days": signal_to_brief.target_days,
                "on_target": signal_to_brief.on_target,
                "min_days": signal_to_brief.min_days,
                "max_days": signal_to_brief.max_days,
                "sample_count": signal_to_brief.sample_count,
            },
            "brief_to_s2": {
                "avg_days": brief_to_s2.avg_days,
                "target_days": brief_to_s2.target_days,
                "on_target": brief_to_s2.on_target,
                "min_days": brief_to_s2.min_days,
                "max_days": brief_to_s2.max_days,
                "sample_count": brief_to_s2.sample_count,
            },
        }

    async def _generate_alerts(
        self, metrics: dict[str, Any], lead_times: dict[str, Any]
    ) -> list[Alert]:
        """ê²½ê³  ìƒì„±"""
        alerts = []

        # ëª©í‘œ ë¯¸ë‹¬ ê²½ê³ 
        for key in ["activity", "signal", "brief"]:
            achievement = metrics[key]["achievement"]
            if achievement < 80:
                severity = determine_severity(achievement)
                alerts.append(
                    Alert(
                        type=AlertType.UNDER_TARGET.value,
                        severity=severity,
                        metric=key,
                        message=f"{key.capitalize()} ëª©í‘œ ëŒ€ë¹„ {achievement:.1f}% ë‹¬ì„±",
                        details={
                            "actual": metrics[key]["actual"],
                            "target": metrics[key]["target"],
                        },
                    )
                )

        # S2 ëª©í‘œ í™•ì¸
        s2_actual = metrics["s2"]["actual"]
        s2_min = metrics["s2"]["target_min"]
        if s2_actual < s2_min:
            alerts.append(
                Alert(
                    type=AlertType.UNDER_TARGET.value,
                    severity=AlertSeverity.YELLOW.value,
                    metric="s2",
                    message=f"S2 {s2_actual}ê±´ (ëª©í‘œ: {s2_min}~{metrics['s2']['target_max']}ê±´)",
                    details={
                        "actual": s2_actual,
                        "target_min": s2_min,
                        "target_max": metrics["s2"]["target_max"],
                    },
                )
            )

        # ë¦¬ë“œíƒ€ì„ ì´ˆê³¼ ê²½ê³ 
        for key, data in lead_times.items():
            if not data["on_target"]:
                alerts.append(
                    Alert(
                        type=AlertType.LEAD_TIME_EXCEEDED.value,
                        severity=AlertSeverity.YELLOW.value,
                        metric=key,
                        message=f"{key.replace('_', ' ').title()} í‰ê·  {data['avg_days']:.1f}ì¼ (ëª©í‘œ: {data['target_days']}ì¼)",
                        details={
                            "avg_days": data["avg_days"],
                            "target_days": data["target_days"],
                            "max_days": data.get("max_days", 0),
                        },
                    )
                )

        return alerts

    async def _get_top_plays(self, start: datetime, end: datetime) -> list[TopPlay]:
        """Top Plays ì„ ì • (Mock ë°ì´í„°)"""
        # ì‹¤ì œ êµ¬í˜„ì€ DBì—ì„œ Signal/Brief ìˆ˜ ê¸°ì¤€ ì •ë ¬

        return [
            TopPlay(
                rank=1,
                play_id="EXT_Desk_D01_Seminar",
                play_name="ëŒ€ì™¸ ì„¸ë¯¸ë‚˜ ë¦¬ì„œì¹˜",
                signal_count=12,
                brief_count=3,
                s2_count=1,
                owner="ê¹€ì—ì´ì „íŠ¸",
            ),
            TopPlay(
                rank=2,
                play_id="KT_Sales_S01_Interview",
                play_name="KT ì˜ì—…PM ì¸í„°ë·°",
                signal_count=8,
                brief_count=2,
                s2_count=1,
                owner="ì´ë§¤ë‹ˆì €",
            ),
            TopPlay(
                rank=3,
                play_id="KT_Inbound_I01",
                play_name="KT ì¸ë°”ìš´ë“œ Triage",
                signal_count=6,
                brief_count=2,
                s2_count=0,
                owner="ë°•ë‹´ë‹¹",
            ),
        ]

    async def _get_status_summary(self) -> dict[str, int]:
        """Play ìƒíƒœ ìš”ì•½ (Mock ë°ì´í„°)"""
        return {
            "green": 8,
            "yellow": 3,
            "red": 1,
            "total": 12,
        }

    def _generate_recommendations(self, metrics: dict[str, Any], alerts: list[Alert]) -> list[str]:
        """ì¶”ì²œ ì‚¬í•­ ìƒì„±"""
        recommendations = []

        # ê²½ê³  ê¸°ë°˜ ì¶”ì²œ
        under_target_metrics = [a.metric for a in alerts if a.type == AlertType.UNDER_TARGET.value]

        if "activity" in under_target_metrics:
            recommendations.append("ğŸ“Œ Activity ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•´ ì„¸ë¯¸ë‚˜/ì¸í„°ë·° ì¶”ê°€ ê³„íš í•„ìš”")

        if "signal" in under_target_metrics:
            recommendations.append(
                "ğŸ“Œ Signal ì¶”ì¶œ íš¨ìœ¨í™”: ê¸°ì¡´ Activity ì¬ê²€í†  ë˜ëŠ” ìƒˆë¡œìš´ ì›ì²œ íƒìƒ‰"
            )

        if "brief" in under_target_metrics:
            recommendations.append(
                "ğŸ“Œ Brief ì „í™˜ìœ¨ í–¥ìƒ: ëŒ€ê¸° ì¤‘ì¸ Signal Scorecard í‰ê°€ ìš°ì„  ì§„í–‰"
            )

        # ë¦¬ë“œíƒ€ì„ ì´ˆê³¼
        lead_time_alerts = [a for a in alerts if a.type == AlertType.LEAD_TIME_EXCEEDED.value]

        if lead_time_alerts:
            recommendations.append("â±ï¸ ë¦¬ë“œíƒ€ì„ ë‹¨ì¶•: ë³‘ëª© êµ¬ê°„ ë¶„ì„ ë° í”„ë¡œì„¸ìŠ¤ ê°œì„  ê²€í† ")

        # ì„±ê³¼ ì¢‹ì„ ë•Œ
        if not recommendations:
            all_good = all(
                metrics[k]["achievement"] >= 100 for k in ["activity", "signal", "brief"]
            )
            if all_good:
                recommendations.append("ğŸ‰ ëª¨ë“  KPI ëª©í‘œ ë‹¬ì„±! í˜„ì¬ í˜ì´ìŠ¤ ìœ ì§€")
            else:
                recommendations.append("âœ… ëŒ€ë¶€ë¶„ì˜ KPIê°€ ì–‘í˜¸í•©ë‹ˆë‹¤. ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ ê¶Œì¥")

        return recommendations

    async def _publish_report(
        self,
        period: str,
        metrics: dict[str, Any],
        lead_times: dict[str, Any],
        alerts: list[Alert],
        top_plays: list[TopPlay],
        recommendations: list[str],
    ) -> str:
        """Confluenceì— ë¦¬í¬íŠ¸ ê²Œì‹œ"""
        # TODO: Confluence MCP ì—°ë™
        self.logger.info("Publishing KPI report to Confluence")
        return ""

    async def _send_notifications(self, confluence_url: str, alerts: list[Alert]) -> None:
        """Teams/Slack ì•Œë¦¼ ì „ì†¡"""
        # TODO: Teams MCP ì—°ë™
        red_alerts = [a for a in alerts if a.severity == AlertSeverity.RED.value]
        if red_alerts:
            self.logger.warning(
                "Sending RED alert notifications",
                count=len(red_alerts),
            )


# ============================================================
# AG-UI ì´ë²¤íŠ¸ ë°œí–‰ ë²„ì „
# ============================================================


class KPIDigestPipelineWithEvents(KPIDigestPipeline):
    """
    WF-05: KPI Digest with AG-UI Events

    ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ë°œí–‰ì„ í¬í•¨í•œ KPI Digest íŒŒì´í”„ë¼ì¸
    """

    def __init__(self, emitter: "WorkflowEventEmitter"):
        super().__init__()
        self.emitter = emitter
        self.logger = logger.bind(workflow="WF-05", with_events=True)

    async def run(self, input_data: KPIInput) -> KPIDigestOutput:
        """ì›Œí¬í”Œë¡œ ì‹¤í–‰ (ì´ë²¤íŠ¸ ë°œí–‰ í¬í•¨)"""
        self.logger.info("Starting KPI Digest with events", period=input_data.period)

        # ì‹¤í–‰ ì‹œì‘ ì´ë²¤íŠ¸
        await self.emitter.emit_run_started(
            workflow_id="WF-05",
            input_data={
                "period": input_data.period,
                "notify": input_data.notify,
            },
            steps=self.STEPS,
        )

        try:
            # Step 1: ê¸°ê°„ ê³„ì‚°
            await self.emitter.emit_step_started(
                step_id="PERIOD_CALC",
                step_index=0,
                step_label="ê¸°ê°„ ê³„ì‚°",
                message=f"{input_data.period} ê¸°ê°„ì„ ê³„ì‚°í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
            )

            period_start, period_end = calculate_period_range(input_data.period)

            await self.emitter.emit_step_finished(
                step_id="PERIOD_CALC",
                step_index=0,
                result={
                    "start": period_start.isoformat(),
                    "end": period_end.isoformat(),
                },
            )

            # Step 2: ë©”íŠ¸ë¦­ ì§‘ê³„
            await self.emitter.emit_step_started(
                step_id="METRICS_AGGREGATE",
                step_index=1,
                step_label="ë©”íŠ¸ë¦­ ì§‘ê³„",
                message="Activity, Signal, Brief, S2 ë©”íŠ¸ë¦­ì„ ì§‘ê³„í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
            )

            metrics = await self._aggregate_metrics(period_start, period_end, input_data.play_ids)

            await self.emitter.emit_surface(
                surface_id="metrics-summary",
                surface={
                    "id": "metrics-summary",
                    "type": "kpi_metrics",
                    "title": "KPI ë©”íŠ¸ë¦­ ìš”ì•½",
                    "metrics": {
                        "activity": metrics["activity"],
                        "signal": metrics["signal"],
                        "brief": metrics["brief"],
                        "s2": metrics["s2"],
                    },
                },
            )

            await self.emitter.emit_step_finished(
                step_id="METRICS_AGGREGATE",
                step_index=1,
                result={"metrics_collected": True},
            )

            # Step 3: ë¦¬ë“œíƒ€ì„ ê³„ì‚°
            await self.emitter.emit_step_started(
                step_id="LEAD_TIME_CALC",
                step_index=2,
                step_label="ë¦¬ë“œíƒ€ì„ ê³„ì‚°",
                message="Signalâ†’Brief, Briefâ†’S2 ë¦¬ë“œíƒ€ì„ì„ ê³„ì‚°í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
            )

            lead_times = await self._calculate_lead_times(period_start, period_end)

            await self.emitter.emit_surface(
                surface_id="lead-times",
                surface={
                    "id": "lead-times",
                    "type": "lead_times",
                    "title": "ë¦¬ë“œíƒ€ì„ ë¶„ì„",
                    "lead_times": lead_times,
                },
            )

            await self.emitter.emit_step_finished(
                step_id="LEAD_TIME_CALC",
                step_index=2,
                result=lead_times,
            )

            # Step 4: ê²½ê³  ìƒì„±
            await self.emitter.emit_step_started(
                step_id="ALERTS_GENERATE",
                step_index=3,
                step_label="ê²½ê³  ìƒì„±",
                message="ëª©í‘œ ë¯¸ë‹¬ ë° ì§€ì—° í•­ëª©ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
            )

            alerts = await self._generate_alerts(metrics, lead_times)

            if alerts:
                await self.emitter.emit_surface(
                    surface_id="alerts",
                    surface={
                        "id": "alerts",
                        "type": "kpi_alerts",
                        "title": f"ê²½ê³  {len(alerts)}ê±´",
                        "alerts": [self._alert_to_dict(a) for a in alerts],
                    },
                )

            await self.emitter.emit_step_finished(
                step_id="ALERTS_GENERATE",
                step_index=3,
                result={"alerts_count": len(alerts)},
            )

            # Step 5: Top Plays ì„ ì •
            await self.emitter.emit_step_started(
                step_id="TOP_PLAYS",
                step_index=4,
                step_label="Top Plays ì„ ì •",
                message="ì„±ê³¼ ìš°ìˆ˜ Playë¥¼ ì„ ì •í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
            )

            top_plays = await self._get_top_plays(period_start, period_end)

            await self.emitter.emit_surface(
                surface_id="top-plays",
                surface={
                    "id": "top-plays",
                    "type": "leaderboard",
                    "title": "Top Plays",
                    "plays": [self._top_play_to_dict(p) for p in top_plays],
                },
            )

            await self.emitter.emit_step_finished(
                step_id="TOP_PLAYS",
                step_index=4,
                result={"top_plays_count": len(top_plays)},
            )

            # Step 6: ì¶”ì²œ ì‚¬í•­ ìƒì„±
            await self.emitter.emit_step_started(
                step_id="RECOMMENDATIONS",
                step_index=5,
                step_label="ì¶”ì²œ ì‚¬í•­ ìƒì„±",
                message="ê°œì„  ê¶Œê³ ì‚¬í•­ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
            )

            recommendations = []
            if input_data.include_recommendations:
                recommendations = self._generate_recommendations(metrics, alerts)

            status_summary = await self._get_status_summary()

            await self.emitter.emit_step_finished(
                step_id="RECOMMENDATIONS",
                step_index=5,
                result={"recommendations_count": len(recommendations)},
            )

            # Confluence ë°œí–‰ (ì„ íƒ)
            confluence_url = None
            if input_data.notify:
                confluence_url = await self._publish_report(
                    input_data.period, metrics, lead_times, alerts, top_plays, recommendations
                )
                await self._send_notifications(confluence_url, alerts)

            # ê²°ê³¼ ìƒì„±
            result = KPIDigestOutput(
                period=input_data.period,
                period_start=period_start.isoformat(),
                period_end=period_end.isoformat(),
                metrics=metrics,
                lead_times=lead_times,
                alerts=[self._alert_to_dict(a) for a in alerts],
                top_plays=[self._top_play_to_dict(p) for p in top_plays],
                recommendations=recommendations,
                status_summary=status_summary,
                confluence_url=confluence_url,
                generated_at=datetime.now(UTC).isoformat(),
            )

            # ì‹¤í–‰ ì™„ë£Œ ì´ë²¤íŠ¸
            await self.emitter.emit_run_finished(
                result={
                    "period": result.period,
                    "alerts_count": len(alerts),
                    "recommendations_count": len(recommendations),
                }
            )

            return result

        except Exception as e:
            self.logger.error("Pipeline error", error=str(e))
            await self.emitter.emit_run_error(str(e), recoverable=False)
            raise


# ============================================================
# DB ì—°ë™ ë²„ì „
# ============================================================


class KPIDigestPipelineWithDB(KPIDigestPipelineWithEvents):
    """
    WF-05: KPI Digest with DB Integration

    ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ì„ í¬í•¨í•œ ì™„ì „í•œ íŒŒì´í”„ë¼ì¸
    """

    def __init__(self, emitter: "WorkflowEventEmitter", db: "AsyncSession"):
        super().__init__(emitter)
        self.db = db
        self.logger = logger.bind(workflow="WF-05", with_db=True)

    async def _aggregate_metrics(
        self, start: datetime, end: datetime, play_ids: list[str] | None
    ) -> dict[str, Any]:
        """DB ê¸°ë°˜ ë©”íŠ¸ë¦­ ì§‘ê³„"""
        from backend.database.repositories.play_record import play_record_repo
        from backend.database.repositories.signal import signal_repo

        # PlayRecordì—ì„œ ì „ì²´ í†µê³„ ê°€ì ¸ì˜¤ê¸°
        stats = await play_record_repo.get_stats(self.db)

        # ì£¼ê°„/ì›”ê°„ ëª©í‘œ ì„¤ì •
        period_days = (end - start).days + 1
        multiplier = period_days / 7  # ì£¼ê°„ ê¸°ì¤€ ë°°ìˆ˜

        activity_target = int(self.targets.activity_weekly * multiplier)
        signal_target = int(self.targets.signal_weekly * multiplier)
        brief_target = int(self.targets.brief_weekly * multiplier)

        # Signal ì›ì²œë³„ í†µê³„
        by_source = {}
        for source in ["KT", "ê·¸ë£¹ì‚¬", "ëŒ€ì™¸"]:
            items, count = await signal_repo.get_multi_filtered(
                self.db, source=source, skip=0, limit=1000
            )
            by_source[source] = {
                "signal": count,
            }

        return {
            "activity": {
                "actual": stats["total_activity"],
                "target": activity_target,
                "achievement": calculate_achievement(stats["total_activity"], activity_target),
            },
            "signal": {
                "actual": stats["total_signal"],
                "target": signal_target,
                "achievement": calculate_achievement(stats["total_signal"], signal_target),
            },
            "brief": {
                "actual": stats["total_brief"],
                "target": brief_target,
                "achievement": calculate_achievement(stats["total_brief"], brief_target),
            },
            "s2": {
                "actual": stats["total_s2"],
                "target_min": self.targets.s2_weekly_min,
                "target_max": self.targets.s2_weekly_max,
                "achievement": calculate_achievement(stats["total_s2"], self.targets.s2_weekly_min),
            },
            "s3": {
                "actual": stats["total_s3"],
                "target": 1,
                "achievement": calculate_achievement(stats["total_s3"], 1),
            },
            "by_source": by_source,
        }

    async def _calculate_lead_times(self, start: datetime, end: datetime) -> dict[str, Any]:
        """DB ê¸°ë°˜ ë¦¬ë“œíƒ€ì„ ê³„ì‚°"""

        # Signal â†’ Brief ë¦¬ë“œíƒ€ì„ (Briefê°€ ìˆëŠ” Signal ê¸°ì¤€)
        # TODO: ì‹¤ì œ êµ¬í˜„ì€ Signal.created_atê³¼ Brief.created_at ì°¨ì´ ê³„ì‚°
        signal_to_brief_days: list[float] = []

        # Brief â†’ S2 ë¦¬ë“œíƒ€ì„ (VALIDATED ìƒíƒœì¸ Brief ê¸°ì¤€)
        # TODO: Brief.created_atê³¼ validation ì™„ë£Œ ì‹œì  ì°¨ì´ ê³„ì‚°
        brief_to_s2_days: list[float] = []

        # Mock ë°ì´í„° (ì‹¤ì œ êµ¬í˜„ ì‹œ DB ì¿¼ë¦¬ë¡œ ëŒ€ì²´)
        signal_to_brief_avg = (
            5.2
            if not signal_to_brief_days
            else sum(signal_to_brief_days) / len(signal_to_brief_days)
        )
        brief_to_s2_avg = (
            11.0 if not brief_to_s2_days else sum(brief_to_s2_days) / len(brief_to_s2_days)
        )

        return {
            "signal_to_brief": {
                "avg_days": signal_to_brief_avg,
                "target_days": self.targets.signal_to_brief_days,
                "on_target": signal_to_brief_avg <= self.targets.signal_to_brief_days,
                "sample_count": len(signal_to_brief_days) or 8,
            },
            "brief_to_s2": {
                "avg_days": brief_to_s2_avg,
                "target_days": self.targets.brief_to_s2_days,
                "on_target": brief_to_s2_avg <= self.targets.brief_to_s2_days,
                "sample_count": len(brief_to_s2_days) or 3,
            },
        }

    async def _get_top_plays(self, start: datetime, end: datetime) -> list[TopPlay]:
        """DB ê¸°ë°˜ Top Plays ì„ ì •"""
        from backend.database.repositories.play_record import play_record_repo

        leaderboard = await play_record_repo.get_leaderboard(self.db)

        top_plays = []
        for i, play_data in enumerate(leaderboard.get("top_plays", [])[:5]):
            top_plays.append(
                TopPlay(
                    rank=i + 1,
                    play_id=play_data["play_id"],
                    play_name=play_data.get("play_name", play_data["play_id"]),
                    signal_count=play_data.get("signal_qtd", 0),
                    brief_count=play_data.get("brief_qtd", 0),
                    s2_count=0,  # TODO: S2 count ì¶”ê°€
                    owner=None,
                )
            )

        return top_plays

    async def _get_status_summary(self) -> dict[str, int]:
        """DB ê¸°ë°˜ Play ìƒíƒœ ìš”ì•½"""
        from backend.database.repositories.play_record import play_record_repo

        alerts_data = await play_record_repo.get_alerts(self.db)

        green_count = await self._count_plays_by_status("G")
        yellow_count = len(alerts_data.get("yellow_plays", []))
        red_count = len(alerts_data.get("red_plays", []))

        return {
            "green": green_count,
            "yellow": yellow_count,
            "red": red_count,
            "total": green_count + yellow_count + red_count,
        }

    async def _count_plays_by_status(self, status: str) -> int:
        """íŠ¹ì • ìƒíƒœì˜ Play ìˆ˜ ì¡°íšŒ"""
        from backend.database.repositories.play_record import play_record_repo

        items, total = await play_record_repo.get_multi_filtered(
            self.db, status=status, skip=0, limit=1
        )
        return total


# ============================================================
# ì›Œí¬í”Œë¡œ ì¸ìŠ¤í„´ìŠ¤ ë° ì§„ì…ì 
# ============================================================

workflow = KPIDigestPipeline()


async def run(input_data: dict[str, Any]) -> dict[str, Any]:
    """ì›Œí¬í”Œë¡œ ì§„ì…ì """
    kpi_input = KPIInput(
        period=input_data.get("period", "week"),
        play_ids=input_data.get("play_ids"),
        notify=input_data.get("notify", False),
        include_recommendations=input_data.get("include_recommendations", True),
    )

    result = await workflow.run(kpi_input)

    return {
        "period": result.period,
        "period_start": result.period_start,
        "period_end": result.period_end,
        "metrics": result.metrics,
        "lead_times": result.lead_times,
        "alerts": result.alerts,
        "top_plays": result.top_plays,
        "recommendations": result.recommendations,
        "status_summary": result.status_summary,
        "confluence_url": result.confluence_url,
        "generated_at": result.generated_at,
    }


async def run_with_events(
    input_data: dict[str, Any], emitter: "WorkflowEventEmitter"
) -> dict[str, Any]:
    """ì´ë²¤íŠ¸ ë°œí–‰ì„ í¬í•¨í•œ ì›Œí¬í”Œë¡œ ì‹¤í–‰"""
    kpi_input = KPIInput(
        period=input_data.get("period", "week"),
        play_ids=input_data.get("play_ids"),
        notify=input_data.get("notify", False),
        include_recommendations=input_data.get("include_recommendations", True),
    )

    pipeline = KPIDigestPipelineWithEvents(emitter)
    result = await pipeline.run(kpi_input)

    return {
        "period": result.period,
        "period_start": result.period_start,
        "period_end": result.period_end,
        "metrics": result.metrics,
        "lead_times": result.lead_times,
        "alerts": result.alerts,
        "top_plays": result.top_plays,
        "recommendations": result.recommendations,
        "status_summary": result.status_summary,
        "confluence_url": result.confluence_url,
        "generated_at": result.generated_at,
    }


# íƒ€ì… íŒíŠ¸ë¥¼ ìœ„í•œ import (ìˆœí™˜ ì°¸ì¡° ë°©ì§€)
if __name__ != "__main__":
    from sqlalchemy.ext.asyncio import AsyncSession

    from backend.agent_runtime.event_manager import WorkflowEventEmitter
