# Eval Task 템플릿
# 이 파일을 복사하여 새로운 Task를 정의하세요

task:
  # ===== 필수 필드 =====
  id: "{{task-id}}"  # 고유 ID (소문자, 하이픈, 언더스코어만)
  type: workflow  # coding | workflow | conversational | research | computer_use
  desc: "{{task-description}}"
  suite: "{{suite-id}}"  # 소속 Suite ID

  # ===== 메타데이터 (선택) =====
  version: "1.0.0"
  metadata:
    domain: functionality  # security | performance | functionality | ux | integration | data_quality
    difficulty: medium  # trivial | easy | medium | hard | expert
    risk: low  # low | medium | high | critical
    purpose: capability  # capability | regression
    expected_pass_rate: 0.8
    owner: "{{owner-team}}"

  # ===== 입력 설정 =====
  inputs:
    prompt: |
      에이전트에게 전달할 프롬프트를 작성하세요.

      ## 컨텍스트
      {{context}}

      ## 요청
      {{request}}

    # prompt_file: "prompts/my-prompt.md"  # 외부 파일 사용 시

    context:
      key1: "value1"
      key2: "value2"

    # files:  # 초기 파일 설정 (선택)
    #   - path: "src/main.py"
    #     content: |
    #       # 초기 코드

  # ===== 성공 기준 =====
  success_criteria:
    description: "{{success-description}}"

    outcome_checks:
      - type: file_exists
        target: "{{target-file}}"
        description: "필수 파일이 생성되어야 함"

      - type: command_succeeds
        target: "pytest tests/"
        description: "테스트가 통과해야 함"

      # - type: state_equals
      #   target: "db.table.count"
      #   value: 5
      #   description: "DB에 5개 레코드가 있어야 함"

    negative_checks:
      - type: file_not_contains
        target: "**/*.py"
        value: "TODO"
        description: "TODO가 남아있으면 안 됨"

  # ===== Trial 설정 =====
  trials:
    k: 5  # 실행 횟수
    parallel: true  # 병렬 실행
    stop_on_first_pass: false  # 첫 성공 시 중단 여부

  # ===== 환경 설정 =====
  environment:
    sandbox: container  # none | process | container | vm
    # image: "python:3.11-slim"
    reset: clean  # clean | snapshot | persist
    network: internal  # none | internal | external
    # working_dir: "/workspace"

  # ===== 에이전트 설정 =====
  agent:
    adapter: claude_agent_sdk  # claude_agent_sdk | claude_code | langchain | custom
    # agent_id: "orchestrator"  # 특정 에이전트 지정 시
    model: "claude-sonnet-4-20250514"
    max_turns: 20
    max_tool_calls: 50
    # tools_allowed: ["Read", "Write", "Bash"]
    # tools_denied: ["WebFetch"]

  # ===== 채점기 설정 =====
  graders:
    # 결정적 채점기
    - type: deterministic_tests
      id: "pytest-tests"
      weight: 0.4
      required: true
      config:
        test_files: ["tests/test_{{feature}}.py"]
        framework: pytest

    - type: static_analysis
      id: "code-quality"
      weight: 0.2
      config:
        commands:
          - "ruff check backend/"
          - "mypy backend/"
        allow_warnings: false

    # LLM 채점기
    - type: llm_rubric
      id: "quality-rubric"
      weight: 0.4
      config:
        rubric_path: "evals/rubrics/{{feature}}_quality.md"
        model: "claude-sonnet-4-20250514"
        dimensions:
          - name: "completeness"
            description: "요구사항 충족도"
            weight: 0.4
          - name: "code_quality"
            description: "코드 품질"
            weight: 0.3
          - name: "documentation"
            description: "문서화 수준"
            weight: 0.3

  # ===== 채점 방식 =====
  scoring:
    mode: weighted  # weighted | binary | hybrid | partial_credit
    pass_threshold: 0.8

  # ===== 타임아웃 =====
  timeout:
    total_seconds: 300
    per_turn_seconds: 60
    grading_seconds: 120

  # ===== 태그 =====
  tags:
    - "{{domain}}"
    - "{{feature}}"
